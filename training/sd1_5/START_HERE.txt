â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘             INSTRUCTPIX2PIX TRAINING ON STABLE DIFFUSION 1.5              â•‘
â•‘                    Optimized for 8xA100 GPUs                              â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ WHAT THIS DOES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Train a model to edit images based on text instructions:
  
  Input:  Original Photo + "turn the sky into sunset"
  Output: Edited Photo with sunset sky

Using official HuggingFace Diffusers script (actively maintained)


ğŸ“ YOU ARE HERE: /mnt/localssd/diffusion/training/sd1_5/
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


ğŸš€ QUICK START (4 STEPS)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1ï¸âƒ£  READ THE DOCS
    
    â€¢ WORKFLOW.txt     â† Visual workflow guide (START HERE!)
    â€¢ QUICKREF.md      â† One-page quick reference  
    â€¢ README.md        â† Complete documentation
    â€¢ COMMANDS.sh      â† All commands in one file

2ï¸âƒ£  PREPARE YOUR DATA
    
    See: data_format_examples.txt
    
    Create: my_data/metadata.jsonl with your 50k triplets
    Format: {"input_image": "inputs/001.jpg", "instruction": "text", "output_image": "outputs/001.jpg"}

3ï¸âƒ£  CONVERT & VALIDATE
    
    $ python validate_data.py --data_dir /path/to/my_data
    $ python convert_to_hf_dataset.py --data_dir /path/to/my_data --output_dir ./data_hf

4ï¸âƒ£  TRAIN!
    
    $ pip install -r requirements.txt
    $ ./setup_accelerate.sh
    $ ./train.sh --data_dir ./data_hf


ğŸ“š DOCUMENTATION FILES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

START HERE:
  â–º WORKFLOW.txt              Visual guide with ASCII art
  â–º QUICKREF.md               One-page reference
  â–º COMMANDS.sh               All commands to copy-paste

DETAILED:
  â€¢ README.md                 Complete guide (9KB)
  â€¢ data_format_examples.txt  Data format examples

SCRIPTS:
  â€¢ train_instruct_pix2pix.py Official HuggingFace training script â­
  â€¢ convert_to_hf_dataset.py  Convert your data format
  â€¢ validate_data.py          Check data before training
  â€¢ inference.py              Run trained model
  â€¢ train.sh                  Launch training
  â€¢ quickstart.sh            Automated setup + training


âš¡ FASTEST PATH TO TRAINING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

If you already have your data ready:

  $ cd /mnt/localssd/diffusion/training/sd1_5
  $ pip install -r requirements.txt
  $ python convert_to_hf_dataset.py --data_dir /path/to/data --output_dir ./data_hf
  $ ./setup_accelerate.sh
  $ ./train.sh --data_dir ./data_hf

That's it! Training will take ~1.5-2 days on 8xA100.


ğŸ“Š WHAT TO EXPECT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Hardware:        8 x A100 (80GB)
Training Time:   ~1.5-2 days for 50k samples
VRAM per GPU:    ~35-45 GB
Resolution:      512 Ã— 512
Batch Size:      64 global (8 per GPU)
Model:           Stable Diffusion 1.5 + InstructPix2Pix


ğŸ¨ AFTER TRAINING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Run inference on your trained model:

  $ python inference.py \
      --model_path ./output/instruct-pix2pix-sd15 \
      --input_image photo.jpg \
      --instruction "turn sky into sunset" \
      --output_path result.png


â“ NEED HELP?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Read WORKFLOW.txt for visual guide
2. Read QUICKREF.md for quick reference
3. Read README.md for troubleshooting
4. Check COMMANDS.sh for all commands


ğŸ“– REFERENCES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Paper:  https://arxiv.org/abs/2211.09800 (InstructPix2Pix)
Code:   https://github.com/huggingface/diffusers/examples/instruct_pix2pix
Docs:   https://huggingface.co/docs/diffusers


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

              ğŸ‘‰  READ WORKFLOW.txt NEXT  ğŸ‘ˆ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

