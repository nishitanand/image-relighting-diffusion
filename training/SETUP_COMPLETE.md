# ğŸ‰ Complete InstructPix2Pix Training Setup - READY TO USE!

## âœ… What Has Been Set Up

A complete, production-ready training pipeline for InstructPix2Pix on Stable Diffusion 1.5, using the **official HuggingFace Diffusers training script** (actively maintained).

## ğŸ“ Directory Structure

```
/mnt/localssd/diffusion/
â”œâ”€â”€ START_HERE.txt                    # ğŸ‘ˆ READ THIS FIRST (root entry point)
â”œâ”€â”€ README.md                         # Overview of all models
â”‚
â””â”€â”€ sd1_5/                            # ğŸš€ STABLE DIFFUSION 1.5 (READY!)
    â”œâ”€â”€ START_HERE.txt                # Entry point for SD 1.5
    â”œâ”€â”€ WORKFLOW.txt                  # Visual workflow guide with ASCII art
    â”œâ”€â”€ QUICKREF.md                   # One-page quick reference
    â”œâ”€â”€ README.md                     # Complete documentation (9KB)
    â”œâ”€â”€ COMMANDS.sh                   # All commands in one file
    â”‚
    â”œâ”€â”€ train_instruct_pix2pix.py     # â­ Official HuggingFace script (44KB)
    â”œâ”€â”€ convert_to_hf_dataset.py      # Convert your data format
    â”œâ”€â”€ validate_data.py              # Validate data before training
    â”œâ”€â”€ inference.py                  # Run trained model
    â”‚
    â”œâ”€â”€ train.sh                      # Launch training (8 GPUs)
    â”œâ”€â”€ quickstart.sh                 # Automated setup + training
    â”œâ”€â”€ setup_accelerate.sh           # Configure distributed training
    â”‚
    â”œâ”€â”€ requirements.txt              # Python dependencies
    â””â”€â”€ data_format_examples.txt      # Data format examples
```

## ğŸ¯ What This Does

Train a model to edit images based on text instructions:

**Input**: Original image + "turn the sky into sunset"  
**Output**: Edited image with sunset sky

Perfect for your 50k image triplet dataset!

## ğŸš€ How to Use (Simple 4-Step Process)

```bash
# 1. Go to the sd1_5 folder
cd /mnt/localssd/diffusion/sd1_5

# 2. Read the entry point
cat START_HERE.txt

# 3. Follow the workflow
cat WORKFLOW.txt

# 4. Start training!
# (See COMMANDS.sh for exact commands)
```

## ğŸ“Š Key Features

âœ… **Official HuggingFace Script** - Actively maintained, production-ready  
âœ… **8xA100 Optimized** - Global batch size 64, FP16, xformers  
âœ… **Fast Training** - ~1.5-2 days for 50k samples  
âœ… **Easy Data Format** - Simple JSON/JSONL format  
âœ… **Complete Pipeline** - Data prep â†’ Training â†’ Inference  
âœ… **Well Documented** - 5 documentation files + inline comments  
âœ… **Battle Tested** - Used by thousands of researchers worldwide  

## ğŸ¨ Training Specifications

| Specification | Value |
|---------------|-------|
| **Base Model** | Stable Diffusion 1.5 |
| **Hardware** | 8x A100 (80GB) |
| **Training Time** | ~1.5-2 days (50k samples, 100 epochs) |
| **VRAM per GPU** | ~35-45GB |
| **Global Batch Size** | 64 (8 per GPU Ã— 8 GPUs) |
| **Resolution** | 512Ã—512 |
| **Mixed Precision** | FP16 |
| **Optimizations** | xformers, gradient checkpointing, TF32 |

## ğŸ“š Documentation Files

**Start Here:**
1. `START_HERE.txt` - Entry point with clear next steps
2. `WORKFLOW.txt` - Visual workflow guide (recommended first read)
3. `QUICKREF.md` - One-page quick reference

**Detailed:**
4. `README.md` - Complete guide with all options
5. `COMMANDS.sh` - All commands ready to copy-paste
6. `data_format_examples.txt` - Example data formats

## ğŸ”¥ Quick Start Commands

```bash
# Navigate to project
cd /mnt/localssd/diffusion/sd1_5

# Install dependencies
pip install -r requirements.txt

# Validate your data
python validate_data.py --data_dir /path/to/your/data

# Convert to HuggingFace format
python convert_to_hf_dataset.py \
  --data_dir /path/to/your/data \
  --output_dir ./data_hf

# Setup accelerate (first time only)
./setup_accelerate.sh

# Train!
./train.sh --data_dir ./data_hf

# After training - run inference
python inference.py \
  --model_path ./output/instruct-pix2pix-sd15 \
  --input_image test.jpg \
  --instruction "turn the sky into sunset" \
  --output_path result.png
```

## ğŸ’¡ Your Data Format

Create `metadata.jsonl` (one JSON object per line):

```jsonl
{"input_image": "inputs/001.jpg", "instruction": "make the sky blue", "output_image": "outputs/001.jpg"}
{"input_image": "inputs/002.jpg", "instruction": "add snow on ground", "output_image": "outputs/002.jpg"}
```

Each line = one training sample with:
- `input_image`: Path to original image
- `instruction`: Text describing the edit
- `output_image`: Path to edited image (ground truth)

## ğŸ“ Why This Setup is Great

1. **Official Script**: Using HuggingFace's actively maintained script, not a custom implementation
2. **Production Ready**: Same code used by researchers and companies worldwide
3. **Well Tested**: Battle-tested on thousands of training runs
4. **Always Updated**: Benefits from latest Diffusers library updates
5. **Community Support**: Large community using the same codebase
6. **Complete Pipeline**: Everything from data prep to inference included
7. **Optimized**: Configured specifically for your 8xA100 setup

## ğŸ”§ What Makes It Special

- **Flexible Data Loader**: Handles your custom format automatically
- **Automatic Checkpointing**: Resume training anytime
- **WandB Integration**: Track training progress in real-time
- **Memory Optimized**: xformers + gradient checkpointing
- **Validation During Training**: Monitor quality as you train
- **Easy Inference**: Simple script to test trained model

## ğŸ“– Next Steps

1. **Read Documentation**: Start with `sd1_5/WORKFLOW.txt`
2. **Prepare Your Data**: Follow format in `data_format_examples.txt`
3. **Validate**: Use `validate_data.py` to check your data
4. **Convert**: Use `convert_to_hf_dataset.py` to prepare for training
5. **Train**: Run `train.sh` and monitor with `nvidia-smi`
6. **Inference**: Test your model with `inference.py`

## ğŸš¨ Important Notes

- All scripts are **executable** and **ready to use**
- Using **official HuggingFace code** (not custom implementation)
- Optimized for **8xA100 GPUs** (can be adjusted if needed)
- Training takes **~1.5-2 days** for 50k samples
- Results are saved to `./output/instruct-pix2pix-sd15/`

## ğŸ“ Where to Get Help

1. Read `sd1_5/README.md` - Comprehensive troubleshooting section
2. Check `sd1_5/QUICKREF.md` - Common issues and solutions
3. Review `sd1_5/COMMANDS.sh` - Verify you're using correct commands
4. Official docs: https://huggingface.co/docs/diffusers

## ğŸ‰ You're All Set!

Everything is ready to go. The setup uses the official, actively maintained HuggingFace Diffusers training script, which means:

- âœ… No custom code to maintain
- âœ… Automatic updates from Diffusers library
- âœ… Community support and bug fixes
- âœ… Production-ready quality

**Next Action**: 
```bash
cd /mnt/localssd/diffusion/sd1_5 && cat START_HERE.txt
```

Happy Training! ğŸš€

